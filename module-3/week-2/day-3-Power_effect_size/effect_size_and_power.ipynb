{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What's wrong with (hypothesis significance testing)? Well, among many other things, it does not tell us what we want to know, and we so much want to know what we want to know that, out of desperation, we nevertheless believe that it does! - Cohen\n",
    "\n",
    "__Note__ For this notebook I follow the discussion made in R.R.Pagano, 'Understanding the Statistics in Behaviour Sciences.'\n",
    "\n",
    "# Effect Size\n",
    "\n",
    "## Size of Effect: Significant vs Important \n",
    "\n",
    "Q: Consider the case where we analyzed the results of an social experiment with an hypothesis testing. Suppose at the end we concluded that the results are significant. What do we really mean by this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to explain what we mean: \n",
    "\n",
    "\n",
    "__Scenerio__: Are SAT-Math scores at one college greater than the known population mean of 500?\n",
    "\n",
    "Data are collected from a random sample of 1,200 students at that college. The population standard deviation unknown. Find a one-sample mean test and determine p_value. Then determine whether null hypothesis should be rejected ($\\alpha = 0.05$).\n",
    "\n",
    "-  Write alternative hypothesis here (use one sided altenative hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this pickled object to run the \n",
    "## hypothesis testing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('sample1.pickle', 'rb') as handle:\n",
    "    sample = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-22 supplement.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:  2.896767143560673\n",
      "t:  2.897159299027912\n",
      "p_value:  0.0019170045698055093\n"
     ]
    }
   ],
   "source": [
    "sample.std()\n",
    "sample.mean()\n",
    "pop_mean = 500\n",
    "\n",
    "s = sample.std(ddof = 1) / np.sqrt(len(sample))\n",
    "print('s: ' , s)\n",
    "\n",
    "t = (sample.mean()-pop_mean)/s\n",
    "print('t: ', t)\n",
    "\n",
    "p_value = stats.t.sf(t, df = len(sample) - 1)\n",
    "print('p_value: ', p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=2.8971592990279116, pvalue=0.003834009139611028)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_1samp(sample, popmean=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistics: 2.897\n",
      "p_value is 0.002\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"t-statistics: %.3f\n",
    "p_value is %.3f\"\"\"%(t, p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen's D for measuring effect size\n",
    "\n",
    "It looks like there is a statistically significant difference in the exam scores between our sample and the population. Now question is this difference important?\n",
    "\n",
    "-  Cohen(1988) gave a very simple method for determining the magnitude of the importance.\n",
    "\n",
    "__Case 1:__ When we know the population std!\n",
    "\n",
    "$$ d = \\frac{|\\bar{x} - \\mu |}{\\sigma} $$\n",
    "\n",
    "- $\\bar{x}$ sample mean\n",
    "- $\\mu$ population mean\n",
    "- $\\sigma$ population standard deviation\n",
    "- $|\\cdot|$ absolute value\n",
    "\n",
    "!! Wait a minute is this the same with z-score?\n",
    "\n",
    "__Case 2:__ When the population mean is not available!\n",
    "\n",
    "$$ d = \\frac{|\\bar{x} - \\mu |}{s} $$\n",
    "\n",
    "\n",
    "- $\\bar{x}$ sample mean\n",
    "- $\\mu$ population mean\n",
    "- $s$ sample standard deviation\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Header value of $d$</th>\n",
    "    <th>Header interpretation of d</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.0 - 0.20</td>\n",
    "    <td>small effect</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.20 - 0.79</td>\n",
    "    <td> medium effect</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>$\\geq$ 0.80</td>\n",
    "    <td> large effect</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "__Your turn__ Find the Cohen's d score for the following problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:  0.08366865426415815\n"
     ]
    }
   ],
   "source": [
    "d = (sample.mean()-pop_mean)/sample.std()\n",
    "print('d: ', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect size for two independent samples\n",
    "\n",
    "- Recall that to test whether the mean populations of two samples are equal or not we mainly use two tests:\n",
    "\n",
    "1. Independent two sample t-test \n",
    "\n",
    "<img src=\"img/two_sample_ttest.png\" alt=\"Cohen's d-table\"\n",
    "\ttitle=\"Power of a test\" width=\"650\" />\n",
    "\n",
    "\n",
    "<img src=\"img/pooled_std.png\" alt=\"Cohen's d-table\"\n",
    "\ttitle=\"Power of a test\" width=\"650\" />\n",
    "    \n",
    "- Note that this version of the t-test assumes that the population standard deviations for the samples $\\sigma_{1}$ and $\\sigma_{2}$ are the same.\n",
    "\n",
    "- Unfortunately this is not very realistic assumption most of the time. In that sense, it is suggested to use Welch's test instead of two sample t-test.\n",
    "\n",
    "\n",
    "__Your Turn!__\n",
    "\n",
    "- Load the following samples and determine whether they come from populations with the same means.\n",
    "\n",
    "- Use both two-sample t-test and Welch's test and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load samples - samples are independent of each other\n",
    "with open('sample2.pickle', 'rb') as handle:\n",
    "    sample1 = pickle.load(handle)\n",
    "    \n",
    "with open('sample3.pickle', 'rb') as handle:\n",
    "    sample2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement the formula directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.883667539914073"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load -r 25-35 supplement.py\n",
    "weighted_std = ((len(sample1)-1)*(sample1.std()**2) + (len(sample2)-1)*(sample2.std()**2)) / (len(sample1)+len(sample2)-2)\n",
    "weighted_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use scipy.stats.ttest_ind:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.155308505829187, pvalue=0.24951259925998312)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%load -r 37-38 supplement.py\n",
    "stats.ttest_ind(sample1, sample2, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the same method to apply Welch's t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.0707743452200142, pvalue=0.28677029659477615)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(sample1,sample2, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's discuss whether this difference is important or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some tests there are commonly used measures of effect size. For example, when comparing the difference in two means we often compute Cohen's d which is the difference between the two observed sample means in standard deviation units. \n",
    "\n",
    "$$ \\begin{gather}\n",
    " d = \\frac{\\bar{x}_{1} - \\bar{x}_{2}}{s_{W}}\\\\\n",
    "\\text{where} \\qquad s_{W} = \\sqrt{\\frac{(n_{1}-1)s_{1}^{2} + (n_{2}-1)s_{2}^{2} }{n_{1} + n_{2} - 2}}\n",
    "\\end{gather}$$\n",
    "\n",
    "__Your Turn!__\n",
    "\n",
    "Find Cohen's d for sample1 and sample2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = np.random.normal(loc =100, scale = 5, size = 100)\n",
    "sample2 = np.random.normal(loc = 110, scale = 10, size = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooled_std: 7.156408297991618\n",
      "cohens d: 1.5296873664631825\n"
     ]
    }
   ],
   "source": [
    "nom = ((len(sample1)-1)*sample1.std()**2) + ((len(sample2)-1)*sample2.std()**2)\n",
    "denom = len(sample1)+len(sample2)-2\n",
    "pooled_std = np.sqrt(nom/denom)\n",
    "print('pooled_std:', pooled_std)\n",
    "\n",
    "d2 = abs(sample1.mean()-sample2.mean())/pooled_std\n",
    "print('cohens d:', d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for small sample size we didn't get a significant result but for very big sample size we were able to show that the mean is significantly different from the population. So the take away is, we should support the use of p_values with other statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Power of an Hypothesis Testing\n",
    "\n",
    "- Recall $\\alpha$ is the probability of making Type-I error when the null hypothesis is true.\n",
    "\n",
    "- What about the the probability of making Type - II errors?\n",
    "\n",
    " - (We will call this probability as $\\beta$.)\n",
    " \n",
    "- Power of a statistical test measures an experiment's ability to reject a null-hypothesis when $H_{a}$ is true.\n",
    " \n",
    " Mathematically, the __power__ of an experiment is defined as the probability (1- $\\beta$) that the results of an experiment will allow rejection of the null hypothesis if the independent variable has a real effect.\n",
    "\n",
    "## Relationship between effect size and power\n",
    "\n",
    "- As effect size increases power increases.\n",
    "\n",
    "Let's try to understand this with and example. Suppose we are testing the following hypothesis:\n",
    "\n",
    "- $H_{0}$: The population mean of Class-1 (Class-2) is 38 or less. Equivalently: $\\mu_{1} \\leq 38$\n",
    "\n",
    "- $H_{a}$: The population mean of Class-1 (Class-2) is 38 or more. Equivalently $\\mu_{1} > 38$\n",
    "\n",
    "- significance level $\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Data from Class 1</th>\n",
    "    <th>Data from Class 2</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\mu_{1} = 38$</td>\n",
    "    <td> $\\mu_{2} = 38$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\bar{x}_{1} = 40$</td>\n",
    "    <td>$\\bar{x}_{2} = 40$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sigma_{1} = 10$</td>\n",
    "    <td> $\\sigma_{2} =2$</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "__your turn:__ Effect size for the first population\n",
    "\n",
    "hint:0.20\n",
    "\n",
    "__your turn:__ Effect size for the second population\n",
    "\n",
    "hint: 1\n",
    "\n",
    "\n",
    "- Sampling distribution for the Class-1:\n",
    "\n",
    "$\\mu_{1}  = 38$\n",
    "\n",
    "standard_error = $\\frac{\\sigma_{1}}{\\sqrt{n}} = \\frac{10}{\\sqrt{30}}$\n",
    "\n",
    "- Sampling distribution for the Class-1:\n",
    "\n",
    "$\\mu_{1}  = 38$\n",
    "\n",
    "standard_error = $\\frac{\\sigma_{2}}{\\sqrt{n}}= \\frac{2}{\\sqrt{30}}$\n",
    "\n",
    "Now let's assume $\\alpha = 0.05$\n",
    "\n",
    "- Cut-off for the Class-1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that after this z-score we have only 0.05 of the probability\n",
    "z_cut = stats.norm.ppf(0.95)\n",
    "\n",
    "## Above z_cut is for the standard normal distribution\n",
    "## convert it to our problem\n",
    "\n",
    "x1_bar = 38\n",
    "sigma1 = 10\n",
    "std_error = sigma1/np.sqrt(30)\n",
    "\n",
    "cut_off = z_cut*std_error + x1_bar\n",
    "\n",
    "print('cut-off for class 1 %.2f'%cut_off)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same calculation for class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that after this z-score we have only 0.05 of the probability\n",
    "z_cut = stats.norm.ppf(0.95)\n",
    "\n",
    "## Above z_cut is for the standard normal distribution\n",
    "## convert it to our problem\n",
    "\n",
    "x2_bar = 38\n",
    "sigma2 = 2\n",
    "std_error = sigma2/np.sqrt(30)\n",
    "\n",
    "cut_off = z_cut*std_error + x2_bar\n",
    "\n",
    "print('cut-off for class 1 %.2f'%cut_off)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discuss these findings__\n",
    "\n",
    "## Power calculations\n",
    "\n",
    "\n",
    "<img src=\"img/power1.png\" alt=\"Cohen's d-table\"\n",
    "\ttitle=\"Power of a test\" width=\"650\" />\n",
    "\n",
    "\n",
    "<img src=\"img/power2.png\" alt=\"Cohen's d-table\"\n",
    "\ttitle=\"Power of a test\" width=\"650\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample size, $\\alpha$ and Power\n",
    "\n",
    "\n",
    "- Increasing sample size --> decreases the standard error --> power\n",
    "\n",
    "- $\\alpha:$ Probability of making Type-I error also it defines the rejection region.\n",
    "\n",
    "So the larger the rejection region it is more likely that we will reject the null hypothesis. Therefore:\n",
    "\n",
    "Increasing $\\alpha$ --> increases power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- Null Hypothesis Significance Testing: A Review of an Old and Continuing Controversy - RS Nickerson\n",
    "\n",
    "- [Penn State Statistics Courses](https://newonlinecourses.science.psu.edu/stat200/lesson/6/6.4)\n",
    "\n",
    "- [Statistics For Business and Economics - 9.6](https://www.amazon.com/Statistics-Business-Economics-Book-Only/dp/0324783256)\n",
    "\n",
    "- [G. Privitera, Statistics for Behavioral Sciences - ch-8](https://www.amazon.com/Statistics-Behavioral-Sciences-Gregory-Privitera/dp/1506386253)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
