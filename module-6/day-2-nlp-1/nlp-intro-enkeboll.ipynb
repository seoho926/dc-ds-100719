{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining\n",
    "\n",
    "<img src=\"img/text-miners.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is text mining different? What is text?\n",
    "\n",
    "- Order the words from **SMALLEST** to **LARGEST** units\n",
    " - character\n",
    " - corpora\n",
    " - sentence\n",
    " - word\n",
    " - corpus\n",
    " - paragraph\n",
    " - document\n",
    "\n",
    "(after it is all organized)\n",
    "\n",
    "- Any disagreements about the terms used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "## start small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_test = \"Here is a sentence. Or two, I don't think there will be more.\"\n",
    "token_test_2 = \"i thought this sentence was good.\"\n",
    "token_test_3 = \"Here's a sentence... maybe two. Depending on how you like to count!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here is a sentence', \" Or two, I don't think there will be more\", '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's tokenize a document... into sentences\n",
    "def make_sentences(doc):\n",
    "    return doc.split('.')\n",
    "\n",
    "make_sentences(token_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sentence.',\n",
       " 'Or',\n",
       " 'two,',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'think',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'more.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's tokenize a document into words\n",
    "# with these 3 test cases what would you look out for?\n",
    "def tokenize_it(doc):\n",
    "    return doc.split(' ')\n",
    "\n",
    "tokenize_it(token_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New library!\n",
    "\n",
    "while we have seen language processing tools in spark, NLTK is its own python library. And of course, it has its own [documentation](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "resp = requests.get('http://www.gutenberg.org/cache/epub/5200/pg5200.txt')\n",
    "metamorph = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg EBook of Metamorphosis, by Franz Kafka\r\n",
      "Translated by David Wyllie.\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r\n",
      "with this eBook or online at www.gutenberg.net\r\n",
      "\r\n",
      "** This is a COPYRIGHTED Project Gutenberg eBook, Details Below **\r\n",
      "**     Please follow the copyright guidelines in this file.     **\r\n",
      "\r\n",
      "\r\n",
      "Title: Metamorphosis\r\n",
      "\r\n",
      "Author: Franz Kafka\r\n",
      "\r\n",
      "Translator: David Wyllie\r\n",
      "\r\n",
      "Release Date: August 16, 2005 [EBook #5200]\r\n",
      "First posted: May 13, 2002\r\n",
      "Last updated: May 20, 2012\r\n",
      "\r\n",
      "Language: English\r\n",
      "\r\n",
      "\r\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK METAMORPHOSIS ***\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Copyright (C) 2002 David Wyllie.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  Metamorphosis\r\n",
      "  Franz Kafka\r\n",
      "\r\n",
      "Translated by David Wyllie\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "I\r\n",
      "\r\n",
      "\r\n",
      "One morning, when Gregor Samsa woke from troubled dreams, he found\r\n",
      "himself transformed in his bed into a horrible vermin.\n"
     ]
    }
   ],
   "source": [
    "print(metamorph[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your article here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'looked', \"What's\", 'happened', 'to', 'me', 'he', 'thought', 'It', \"wasn't\", 'a', 'dream', 'His', 'room', 'a', 'proper', 'human', 'room', 'although', 'a', 'little', 'too', 'small', 'lay', 'peacefully', 'between', 'its', 'four', 'familiar', 'walls', 'A', 'collection', 'of', 'textile', 'samples', 'lay', 'spread', 'out', 'on', 'the', 'table', 'Samsa', 'was', 'a', 'travelling', 'salesman', 'and', 'above', 'it', 'there', 'hung', 'a', 'picture', 'that', 'he', 'had', 'recently', 'cut', 'out', 'of', 'an', 'illustrated', 'magazine', 'and', 'housed', 'in', 'a', 'nice', 'gilded', 'frame', 'It', 'showed', 'a', 'lady', 'fitted', 'out', 'with', 'a', 'fur', 'hat', 'and', 'fur', 'boa', 'who', 'sat', 'upright', 'raising', 'a', 'heavy', 'fur', 'muff', 'that', 'covered', 'the', 'whole', 'of', 'her', 'lower', 'arm', 'towards']\n"
     ]
    }
   ],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "metamorph_tokens_raw = nltk.regexp_tokenize(metamorph, pattern)\n",
    "print(metamorph_tokens_raw[200:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'metamorphosis', 'by', 'franz', 'kafka', 'translated', 'by', 'david', 'wyllie', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'this', 'is', 'a', 'copyrighted', 'project', 'gutenberg', 'ebook', 'details', 'below', 'please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file', 'title', 'metamorphosis', 'author', 'franz', 'kafka', 'translator', 'david', 'wyllie', 'release', 'date', 'august', 'ebook', 'first', 'posted', 'may', 'last', 'updated', 'may', 'language', 'english', 'start', 'of', 'this']\n"
     ]
    }
   ],
   "source": [
    "metamorph_tokens = [i.lower() for i in metamorph_tokens_raw]\n",
    "print(metamorph_tokens[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'metamorphosis', 'franz', 'kafka', 'translated', 'david', 'wyllie', 'ebook', 'use', 'anyone', 'anywhere', 'cost', 'almost', 'restrictions', 'whatsoever', 'may', 'copy', 'give', 'away', 'use', 'terms', 'project', 'gutenberg', 'license', 'included', 'ebook', 'online', 'www', 'gutenberg', 'net', 'copyrighted', 'project', 'gutenberg', 'ebook', 'details', 'please', 'follow', 'copyright', 'guidelines', 'file', 'title', 'metamorphosis', 'author', 'franz', 'kafka', 'translator', 'david', 'wyllie', 'release', 'date', 'august', 'ebook', 'first', 'posted', 'may', 'last', 'updated', 'may', 'language', 'english', 'start', 'project', 'gutenberg', 'ebook', 'metamorphosis', 'copyright', 'c', 'david', 'wyllie', 'metamorphosis', 'franz', 'kafka', 'translated', 'david', 'wyllie', 'one', 'morning', 'gregor', 'samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'back', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "metamorph_tokens_stopped = [w for w in metamorph_tokens if not w in stop_words]\n",
    "print(metamorph_tokens_stopped[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming / Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming - Porter Stemmer \n",
    "<img src=\"https://cdn.homebrewersassociation.org/wp-content/uploads/Baltic_Porter_Feature-600x800.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "example = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "           'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "           'meeting', 'stating', 'siezing', 'itemization',\n",
    "           'sensational', 'traditional', 'reference', 'colonizer',\n",
    "           'plotted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress fli die mule deni die agre own humbl size meet state siez item sensat tradit refer colon plot\n"
     ]
    }
   ],
   "source": [
    "singles = [stemmer.stem(e) for e in example]\n",
    "print(*singles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming - Snowball Stemmer\n",
    "<img src=\"https://localtvwiti.files.wordpress.com/2018/08/gettyimages-936380496.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic\n",
      "danish\n",
      "dutch\n",
      "english\n",
      "finnish\n",
      "french\n",
      "german\n",
      "hungarian\n",
      "italian\n",
      "norwegian\n",
      "porter\n",
      "portuguese\n",
      "romanian\n",
      "russian\n",
      "spanish\n",
      "swedish\n"
     ]
    }
   ],
   "source": [
    "print(*SnowballStemmer.languages, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "print(stemmer.stem(\"running\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter vs Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous\n",
      "gener\n"
     ]
    }
   ],
   "source": [
    "print(SnowballStemmer(\"english\").stem(\"generously\"))\n",
    "print(SnowballStemmer(\"porter\").stem(\"generously\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Snowball on Metamorphosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('project', 'project')\n",
      "('gutenberg', 'gutenberg')\n",
      "('ebook', 'ebook')\n",
      "('metamorphosis', 'metamorphosi')\n",
      "('franz', 'franz')\n",
      "('kafka', 'kafka')\n",
      "('translated', 'translat')\n",
      "('david', 'david')\n",
      "('wyllie', 'wylli')\n",
      "('ebook', 'ebook')\n",
      "('use', 'use')\n",
      "('anyone', 'anyon')\n",
      "('anywhere', 'anywher')\n",
      "('cost', 'cost')\n",
      "('almost', 'almost')\n",
      "('restrictions', 'restrict')\n",
      "('whatsoever', 'whatsoev')\n",
      "('may', 'may')\n",
      "('copy', 'copi')\n",
      "('give', 'give')\n",
      "('away', 'away')\n",
      "('use', 'use')\n",
      "('terms', 'term')\n",
      "('project', 'project')\n",
      "('gutenberg', 'gutenberg')\n",
      "('license', 'licens')\n",
      "('included', 'includ')\n",
      "('ebook', 'ebook')\n",
      "('online', 'onlin')\n",
      "('www', 'www')\n",
      "('gutenberg', 'gutenberg')\n",
      "('net', 'net')\n",
      "('copyrighted', 'copyright')\n",
      "('project', 'project')\n",
      "('gutenberg', 'gutenberg')\n",
      "('ebook', 'ebook')\n",
      "('details', 'detail')\n",
      "('please', 'pleas')\n",
      "('follow', 'follow')\n",
      "('copyright', 'copyright')\n",
      "('guidelines', 'guidelin')\n",
      "('file', 'file')\n",
      "('title', 'titl')\n",
      "('metamorphosis', 'metamorphosi')\n",
      "('author', 'author')\n",
      "('franz', 'franz')\n",
      "('kafka', 'kafka')\n",
      "('translator', 'translat')\n",
      "('david', 'david')\n",
      "('wyllie', 'wylli')\n",
      "('release', 'releas')\n",
      "('date', 'date')\n",
      "('august', 'august')\n",
      "('ebook', 'ebook')\n",
      "('first', 'first')\n",
      "('posted', 'post')\n",
      "('may', 'may')\n",
      "('last', 'last')\n",
      "('updated', 'updat')\n",
      "('may', 'may')\n",
      "('language', 'languag')\n",
      "('english', 'english')\n",
      "('start', 'start')\n",
      "('project', 'project')\n",
      "('gutenberg', 'gutenberg')\n",
      "('ebook', 'ebook')\n",
      "('metamorphosis', 'metamorphosi')\n",
      "('copyright', 'copyright')\n",
      "('c', 'c')\n",
      "('david', 'david')\n",
      "('wyllie', 'wylli')\n",
      "('metamorphosis', 'metamorphosi')\n",
      "('franz', 'franz')\n",
      "('kafka', 'kafka')\n",
      "('translated', 'translat')\n",
      "('david', 'david')\n",
      "('wyllie', 'wylli')\n",
      "('one', 'one')\n",
      "('morning', 'morn')\n",
      "('gregor', 'gregor')\n",
      "('samsa', 'samsa')\n",
      "('woke', 'woke')\n",
      "('troubled', 'troubl')\n",
      "('dreams', 'dream')\n",
      "('found', 'found')\n",
      "('transformed', 'transform')\n",
      "('bed', 'bed')\n",
      "('horrible', 'horribl')\n",
      "('vermin', 'vermin')\n",
      "('lay', 'lay')\n",
      "('armour', 'armour')\n",
      "('like', 'like')\n",
      "('back', 'back')\n",
      "('lifted', 'lift')\n",
      "('head', 'head')\n",
      "('little', 'littl')\n",
      "('could', 'could')\n",
      "('see', 'see')\n",
      "('brown', 'brown')\n",
      "('belly', 'belli')\n"
     ]
    }
   ],
   "source": [
    "meta_stemmed = [stemmer.stem(word) for word in metamorph_tokens_stopped]\n",
    "print(*zip(metamorph_tokens_stopped[:100], meta_stemmed[:100]), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n",
      "flying : fly\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "\n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(\"flying :\", lemmatizer.lemmatize(\"flown\", pos='v'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('project', 'NN'),\n",
       " ('gutenberg', 'NN'),\n",
       " ('ebook', 'NN'),\n",
       " ('metamorphosis', 'NN'),\n",
       " ('franz', 'NN'),\n",
       " ('kafka', 'NN'),\n",
       " ('translated', 'VBD'),\n",
       " ('david', 'JJ'),\n",
       " ('wyllie', 'NN'),\n",
       " ('ebook', 'NN')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(metamorph_tokens_stopped)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamorph_lemmas_pos = []\n",
    "for x, y in nltk.pos_tag(metamorph_tokens_stopped):\n",
    "    metamorph_lemmas_pos.append((x, get_wordnet_pos(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slightly', 'r'),\n",
       " ('domed', 'v'),\n",
       " ('divided', 'a'),\n",
       " ('arches', 'n'),\n",
       " ('stiff', 'a'),\n",
       " ('sections', 'n'),\n",
       " ('bedding', 'v'),\n",
       " ('hardly', 'r'),\n",
       " ('able', 'a'),\n",
       " ('cover', 'n'),\n",
       " ('seemed', 'v'),\n",
       " ('ready', 'a'),\n",
       " ('slide', 'a'),\n",
       " ('moment', 'n'),\n",
       " ('many', 'a'),\n",
       " ('legs', 'n'),\n",
       " ('pitifully', 'r'),\n",
       " ('thin', 'a'),\n",
       " ('compared', 'v'),\n",
       " ('size', 'n'),\n",
       " ('rest', 'n'),\n",
       " ('waved', 'v'),\n",
       " ('helplessly', 'r'),\n",
       " ('looked', 'v'),\n",
       " (\"what's\", 'n'),\n",
       " ('happened', 'v'),\n",
       " ('thought', 'a'),\n",
       " ('dream', 'n'),\n",
       " ('room', 'n'),\n",
       " ('proper', 'n'),\n",
       " ('human', 'a'),\n",
       " ('room', 'n'),\n",
       " ('although', 'n'),\n",
       " ('little', 'a'),\n",
       " ('small', 'a'),\n",
       " ('lay', 'v'),\n",
       " ('peacefully', 'r'),\n",
       " ('four', 'n'),\n",
       " ('familiar', 'a'),\n",
       " ('walls', 'n'),\n",
       " ('collection', 'n'),\n",
       " ('textile', 'n'),\n",
       " ('samples', 'n'),\n",
       " ('lay', 'v'),\n",
       " ('spread', 'n'),\n",
       " ('table', 'n'),\n",
       " ('samsa', 'n'),\n",
       " ('travelling', 'v'),\n",
       " ('salesman', 'a'),\n",
       " ('hung', 'a'),\n",
       " ('picture', 'n'),\n",
       " ('recently', 'r'),\n",
       " ('cut', 'v'),\n",
       " ('illustrated', 'a'),\n",
       " ('magazine', 'n'),\n",
       " ('housed', 'v'),\n",
       " ('nice', 'r'),\n",
       " ('gilded', 'v'),\n",
       " ('frame', 'n'),\n",
       " ('showed', 'v'),\n",
       " ('lady', 'a'),\n",
       " ('fitted', 'v'),\n",
       " ('fur', 'n'),\n",
       " ('hat', 'n'),\n",
       " ('fur', 'v'),\n",
       " ('boa', 'n'),\n",
       " ('sat', 'v'),\n",
       " ('upright', 'a'),\n",
       " ('raising', 'v'),\n",
       " ('heavy', 'a'),\n",
       " ('fur', 'a'),\n",
       " ('muff', 'n'),\n",
       " ('covered', 'v'),\n",
       " ('whole', 'a'),\n",
       " ('lower', 'a'),\n",
       " ('arm', 'n'),\n",
       " ('towards', 'n'),\n",
       " ('viewer', 'v'),\n",
       " ('gregor', 'n'),\n",
       " ('turned', 'v'),\n",
       " ('look', 'n'),\n",
       " ('window', 'n'),\n",
       " ('dull', 'n'),\n",
       " ('weather', 'n'),\n",
       " ('drops', 'n'),\n",
       " ('rain', 'n'),\n",
       " ('could', 'n'),\n",
       " ('heard', 'v'),\n",
       " ('hitting', 'v'),\n",
       " ('pane', 'n'),\n",
       " ('made', 'v'),\n",
       " ('feel', 'n'),\n",
       " ('quite', 'r'),\n",
       " ('sad', 'a'),\n",
       " ('sleep', 'a'),\n",
       " ('little', 'a'),\n",
       " ('bit', 'n'),\n",
       " ('longer', 'r'),\n",
       " ('forget', 'v'),\n",
       " ('nonsense', 'a')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metamorph_lemmas_pos[100:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Lemmatizer on Metamorphosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('slightly', 'slightly')\n",
      "('domed', 'domed')\n",
      "('divided', 'divided')\n",
      "('arches', 'arch')\n",
      "('stiff', 'stiff')\n",
      "('sections', 'section')\n",
      "('bedding', 'bed')\n",
      "('hardly', 'hardly')\n",
      "('able', 'able')\n",
      "('cover', 'cover')\n",
      "('seemed', 'seem')\n",
      "('ready', 'ready')\n",
      "('slide', 'slide')\n",
      "('moment', 'moment')\n",
      "('many', 'many')\n",
      "('legs', 'leg')\n",
      "('pitifully', 'pitifully')\n",
      "('thin', 'thin')\n",
      "('compared', 'compare')\n",
      "('size', 'size')\n",
      "('rest', 'rest')\n",
      "('waved', 'wave')\n",
      "('helplessly', 'helplessly')\n",
      "('looked', 'look')\n",
      "(\"what's\", \"what's\")\n",
      "('happened', 'happen')\n",
      "('thought', 'thought')\n",
      "('dream', 'dream')\n",
      "('room', 'room')\n",
      "('proper', 'proper')\n",
      "('human', 'human')\n",
      "('room', 'room')\n",
      "('although', 'although')\n",
      "('little', 'little')\n",
      "('small', 'small')\n",
      "('lay', 'lay')\n",
      "('peacefully', 'peacefully')\n",
      "('four', 'four')\n",
      "('familiar', 'familiar')\n",
      "('walls', 'wall')\n",
      "('collection', 'collection')\n",
      "('textile', 'textile')\n",
      "('samples', 'sample')\n",
      "('lay', 'lay')\n",
      "('spread', 'spread')\n",
      "('table', 'table')\n",
      "('samsa', 'samsa')\n",
      "('travelling', 'travel')\n",
      "('salesman', 'salesman')\n",
      "('hung', 'hung')\n",
      "('picture', 'picture')\n",
      "('recently', 'recently')\n",
      "('cut', 'cut')\n",
      "('illustrated', 'illustrated')\n",
      "('magazine', 'magazine')\n",
      "('housed', 'house')\n",
      "('nice', 'nice')\n",
      "('gilded', 'gild')\n",
      "('frame', 'frame')\n",
      "('showed', 'show')\n",
      "('lady', 'lady')\n",
      "('fitted', 'fit')\n",
      "('fur', 'fur')\n",
      "('hat', 'hat')\n",
      "('fur', 'fur')\n",
      "('boa', 'boa')\n",
      "('sat', 'sit')\n",
      "('upright', 'upright')\n",
      "('raising', 'raise')\n",
      "('heavy', 'heavy')\n",
      "('fur', 'fur')\n",
      "('muff', 'muff')\n",
      "('covered', 'cover')\n",
      "('whole', 'whole')\n",
      "('lower', 'low')\n",
      "('arm', 'arm')\n",
      "('towards', 'towards')\n",
      "('viewer', 'viewer')\n",
      "('gregor', 'gregor')\n",
      "('turned', 'turn')\n",
      "('look', 'look')\n",
      "('window', 'window')\n",
      "('dull', 'dull')\n",
      "('weather', 'weather')\n",
      "('drops', 'drop')\n",
      "('rain', 'rain')\n",
      "('could', 'could')\n",
      "('heard', 'hear')\n",
      "('hitting', 'hit')\n",
      "('pane', 'pane')\n",
      "('made', 'make')\n",
      "('feel', 'feel')\n",
      "('quite', 'quite')\n",
      "('sad', 'sad')\n",
      "('sleep', 'sleep')\n",
      "('little', 'little')\n",
      "('bit', 'bit')\n",
      "('longer', 'longer')\n",
      "('forget', 'forget')\n",
      "('nonsense', 'nonsense')\n"
     ]
    }
   ],
   "source": [
    "meta_lemmaed = []\n",
    "for word, pos in metamorph_lemmas_pos:\n",
    "    meta_lemmaed.append(lemmatizer.lemmatize(word, pos=pos))\n",
    "print(*zip(metamorph_tokens_stopped[100:200], meta_lemmaed[100:200]), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is a short list of additional considerations when cleaning text:\n",
    "\n",
    "- Handling large documents and large collections of text documents that do not fit into memory.\n",
    "- Extracting text from markup like HTML, PDF, or other structured document formats.\n",
    "- Transliteration of characters from other languages into English.\n",
    "- Decoding Unicode characters into a normalized form, such as UTF8.\n",
    "- Handling of domain specific words, phrases, and acronyms.\n",
    "- Handling or removing numbers, such as dates and amounts.\n",
    "- Locating and correcting common typos and misspellings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_freqdist = FreqDist(meta_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gregor', 298),\n",
       " ('would', 187),\n",
       " ('room', 133),\n",
       " ('could', 120),\n",
       " ('work', 114),\n",
       " ('even', 104),\n",
       " ('father', 102),\n",
       " ('sister', 101),\n",
       " ('door', 97),\n",
       " ('gutenberg', 94),\n",
       " ('mother', 90),\n",
       " ('project', 88),\n",
       " ('back', 83),\n",
       " ('one', 76),\n",
       " ('time', 74),\n",
       " ('way', 66),\n",
       " ('look', 61),\n",
       " ('tm', 57),\n",
       " ('open', 56),\n",
       " ('use', 55),\n",
       " ('get', 52),\n",
       " ('said', 51),\n",
       " ('littl', 49),\n",
       " ('go', 49),\n",
       " ('without', 47),\n",
       " ('first', 45),\n",
       " ('still', 45),\n",
       " ('want', 44),\n",
       " ('like', 43),\n",
       " ('see', 42),\n",
       " ('hand', 41),\n",
       " ('made', 40),\n",
       " ('make', 40),\n",
       " ('head', 39),\n",
       " ('much', 39),\n",
       " ('come', 39),\n",
       " ('day', 38),\n",
       " ('thing', 38),\n",
       " ('move', 38),\n",
       " ('chief', 38),\n",
       " ('thought', 37),\n",
       " ('clerk', 37),\n",
       " ('turn', 36),\n",
       " ('away', 35),\n",
       " ('samsa', 34),\n",
       " ('let', 33),\n",
       " ('bed', 32),\n",
       " ('well', 32),\n",
       " ('went', 32),\n",
       " ('famili', 32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_freqdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1290abed0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "meta_freqdist.plot(30, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "## this step happens after we account for stopwords and lemmas; depending on the library...\n",
    "* we make a **Count Vector**, which is the formal term for a **bag of words**\n",
    "* we use vectors to pass text into machine learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the CountVectorizer method on 'basic_example'\n",
    "basic_example = ['The Data Scientist wants to train a machine to train machine learning models.']\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(basic_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what info can we get from cv?\n",
    "# hint -- look at the docs again\n",
    "cv.transform(basic_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization allows us to compare two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to help see what's happening\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fit the CountVectorizer on the 'basic_example', now we transform 'basic_example'\n",
    "example_vector_doc_1 = cv.transform(basic_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# what is the type\n",
    "\n",
    "print(type(example_vector_doc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t2\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t2\n",
      "  (0, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "# what does it look like\n",
    "\n",
    "print(example_vector_doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  train  wants\n",
       "0     1         1        2       1          1      2      1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize it\n",
    "example_vector_df = pd.DataFrame(example_vector_doc_1.toarray(), columns=cv.get_feature_names())\n",
    "example_vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  train  wants\n",
       "0     1         0        0       0          1      0      0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we compare new text to the CountVectorizer fit on 'basic_example'\n",
    "new_text = ['the data scientist plotted the residual error of her model']\n",
    "new_data = cv.transform(new_text)\n",
    "new_count = pd.DataFrame(new_data.toarray(),columns=cv.get_feature_names())\n",
    "new_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this the object 'sentences' becomes the corpus\n",
    "sentences = ['The Data Scientist wants to train a machine to train machine learning models.',\n",
    "             'the data scientist plotted the residual error of her model in her analysis',\n",
    "             'Her analysis was so good, she won a Kaggle competition.',\n",
    "             'The machine gained sentience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to the docs for count vectorizer, how would we use an ngram\n",
    "# pro tip -- include stop words\n",
    "bigrams = CountVectorizer(stop_words='english', ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x52 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 57 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector = bigrams.fit_transform(sentences)\n",
    "bigram_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 52 features for this corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['analysis',\n",
       " 'analysis good',\n",
       " 'analysis good won',\n",
       " 'competition',\n",
       " 'data',\n",
       " 'data scientist',\n",
       " 'data scientist plotted',\n",
       " 'data scientist wants',\n",
       " 'error',\n",
       " 'error model']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'There are {str(len(bigrams.get_feature_names()))} features for this corpus')\n",
    "bigrams.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>analysis good</th>\n",
       "      <th>analysis good won</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>data scientist</th>\n",
       "      <th>data scientist plotted</th>\n",
       "      <th>data scientist wants</th>\n",
       "      <th>error</th>\n",
       "      <th>error model</th>\n",
       "      <th>...</th>\n",
       "      <th>train</th>\n",
       "      <th>train machine</th>\n",
       "      <th>train machine learning</th>\n",
       "      <th>train machine train</th>\n",
       "      <th>wants</th>\n",
       "      <th>wants train</th>\n",
       "      <th>wants train machine</th>\n",
       "      <th>won</th>\n",
       "      <th>won kaggle</th>\n",
       "      <th>won kaggle competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  analysis good  analysis good won  competition  data  \\\n",
       "0         0              0                  0            0     1   \n",
       "1         1              0                  0            0     1   \n",
       "2         1              1                  1            1     0   \n",
       "3         0              0                  0            0     0   \n",
       "\n",
       "   data scientist  data scientist plotted  data scientist wants  error  \\\n",
       "0               1                       0                     1      0   \n",
       "1               1                       1                     0      1   \n",
       "2               0                       0                     0      0   \n",
       "3               0                       0                     0      0   \n",
       "\n",
       "   error model  ...  train  train machine  train machine learning  \\\n",
       "0            0  ...      2              2                       1   \n",
       "1            1  ...      0              0                       0   \n",
       "2            0  ...      0              0                       0   \n",
       "3            0  ...      0              0                       0   \n",
       "\n",
       "   train machine train  wants  wants train  wants train machine  won  \\\n",
       "0                    1      1            1                    1    0   \n",
       "1                    0      0            0                    0    0   \n",
       "2                    0      0            0                    0    1   \n",
       "3                    0      0            0                    0    0   \n",
       "\n",
       "   won kaggle  won kaggle competition  \n",
       "0           0                       0  \n",
       "1           0                       0  \n",
       "2           1                       1  \n",
       "3           0                       0  \n",
       "\n",
       "[4 rows x 52 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize it\n",
    "bigram_df = pd.DataFrame(bigram_vector.toarray(), columns=bigrams.get_feature_names())\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "## Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing} i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_sentences = ['The Data Scientist wants to train a machine to train machine learning models.',\n",
    "                    'the data scientist plotted the residual error of her model in her analysis',\n",
    "                    'Her analysis was so good, she won a Kaggle competition.',\n",
    "                    'The machine gained sentiance']\n",
    "# take out stop words\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "# fit transform the sentences\n",
    "tfidf_sentences = tfidf.fit_transform(tf_idf_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize it\n",
    "tfidf_df = pd.DataFrame(tfidf_sentences.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>error</th>\n",
       "      <th>gained</th>\n",
       "      <th>good</th>\n",
       "      <th>kaggle</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>model</th>\n",
       "      <th>models</th>\n",
       "      <th>plotted</th>\n",
       "      <th>residual</th>\n",
       "      <th>scientist</th>\n",
       "      <th>sentiance</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610575</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.366739</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  competition      data     error    gained      good    kaggle  \\\n",
       "0  0.000000     0.000000  0.240692  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.325557     0.000000  0.325557  0.412928  0.000000  0.000000  0.000000   \n",
       "2  0.366739     0.465162  0.000000  0.000000  0.000000  0.465162  0.465162   \n",
       "3  0.000000     0.000000  0.000000  0.000000  0.617614  0.000000  0.000000   \n",
       "\n",
       "   learning   machine     model    models   plotted  residual  scientist  \\\n",
       "0  0.305288  0.481384  0.000000  0.305288  0.000000  0.000000   0.240692   \n",
       "1  0.000000  0.000000  0.412928  0.000000  0.412928  0.412928   0.325557   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "3  0.000000  0.486934  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "   sentiance     train     wants       won  \n",
       "0   0.000000  0.610575  0.305288  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.465162  \n",
       "3   0.617614  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>analysis good</th>\n",
       "      <th>analysis good won</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>data scientist</th>\n",
       "      <th>data scientist plotted</th>\n",
       "      <th>data scientist wants</th>\n",
       "      <th>error</th>\n",
       "      <th>error model</th>\n",
       "      <th>...</th>\n",
       "      <th>train</th>\n",
       "      <th>train machine</th>\n",
       "      <th>train machine learning</th>\n",
       "      <th>train machine train</th>\n",
       "      <th>wants</th>\n",
       "      <th>wants train</th>\n",
       "      <th>wants train machine</th>\n",
       "      <th>won</th>\n",
       "      <th>won kaggle</th>\n",
       "      <th>won kaggle competition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  analysis good  analysis good won  competition  data  \\\n",
       "0         0              0                  0            0     1   \n",
       "1         1              0                  0            0     1   \n",
       "2         1              1                  1            1     0   \n",
       "3         0              0                  0            0     0   \n",
       "\n",
       "   data scientist  data scientist plotted  data scientist wants  error  \\\n",
       "0               1                       0                     1      0   \n",
       "1               1                       1                     0      1   \n",
       "2               0                       0                     0      0   \n",
       "3               0                       0                     0      0   \n",
       "\n",
       "   error model  ...  train  train machine  train machine learning  \\\n",
       "0            0  ...      2              2                       1   \n",
       "1            1  ...      0              0                       0   \n",
       "2            0  ...      0              0                       0   \n",
       "3            0  ...      0              0                       0   \n",
       "\n",
       "   train machine train  wants  wants train  wants train machine  won  \\\n",
       "0                    1      1            1                    1    0   \n",
       "1                    0      0            0                    0    0   \n",
       "2                    0      0            0                    0    1   \n",
       "3                    0      0            0                    0    0   \n",
       "\n",
       "   won kaggle  won kaggle competition  \n",
       "0           0                       0  \n",
       "1           0                       0  \n",
       "2           1                       1  \n",
       "3           0                       0  \n",
       "\n",
       "[4 rows x 52 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compared to bigrams\n",
    "bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's test out our TfidfVectorizer\n",
    "test_tfidf = tfidf.transform(['this is a test document','look at me I am a test document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x18 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a vector\n",
    "test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>error</th>\n",
       "      <th>gained</th>\n",
       "      <th>good</th>\n",
       "      <th>kaggle</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>model</th>\n",
       "      <th>models</th>\n",
       "      <th>plotted</th>\n",
       "      <th>residual</th>\n",
       "      <th>scientist</th>\n",
       "      <th>sentiance</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  competition  data  error  gained  good  kaggle  learning  \\\n",
       "0       0.0          0.0   0.0    0.0     0.0   0.0     0.0       0.0   \n",
       "1       0.0          0.0   0.0    0.0     0.0   0.0     0.0       0.0   \n",
       "\n",
       "   machine  model  models  plotted  residual  scientist  sentiance  train  \\\n",
       "0      0.0    0.0     0.0      0.0       0.0        0.0        0.0    0.0   \n",
       "1      0.0    0.0     0.0      0.0       0.0        0.0        0.0    0.0   \n",
       "\n",
       "   wants  won  \n",
       "0    0.0  0.0  \n",
       "1    0.0  0.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf_df = pd.DataFrame(test_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "test_tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Similarity Between Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell how similar two documents are to one another, normalizing for size, by taking the cosine similarity of the two. \n",
    "\n",
    "This number will range from [0,1], with 0 being not similar whatsoever, and 1 being the exact same. A potential application of cosine similarity is a basic recommendation engine. If you wanted to recommend articles that are most similar to other articles, you could talk the cosine similarity of all articles and return the highest one.\n",
    "\n",
    "<img src=\"./img/better_cos_similarity.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = CountVectorizer()\n",
    "sunday_afternoon = ['Emily ate a burger at burger queen and it was very good.',\n",
    "                    'Emily ate a hot dog at burger prince and it was bad',\n",
    "                    'Emily drove a racecar through your kitchen door',\n",
    "                    'Emily ate a hot dog at burger king and it was bad. I ate a burger at burger queen and it was very good']\n",
    "\n",
    "trial.fit(sunday_afternoon)\n",
    "text_data = trial.transform(sunday_afternoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>at</th>\n",
       "      <th>ate</th>\n",
       "      <th>bad</th>\n",
       "      <th>burger</th>\n",
       "      <th>dog</th>\n",
       "      <th>door</th>\n",
       "      <th>drove</th>\n",
       "      <th>emily</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>it</th>\n",
       "      <th>king</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>prince</th>\n",
       "      <th>queen</th>\n",
       "      <th>racecar</th>\n",
       "      <th>through</th>\n",
       "      <th>very</th>\n",
       "      <th>was</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  at  ate  bad  burger  dog  door  drove  emily  good  ...  it  king  \\\n",
       "0    1   1    1    0       2    0     0      0      1     1  ...   1     0   \n",
       "1    1   1    1    1       1    1     0      0      1     0  ...   1     0   \n",
       "2    0   0    0    0       0    0     1      1      1     0  ...   0     0   \n",
       "3    2   2    2    1       3    1     0      0      1     1  ...   2     1   \n",
       "\n",
       "   kitchen  prince  queen  racecar  through  very  was  your  \n",
       "0        0       0      1        0        0     1    1     0  \n",
       "1        0       1      0        0        0     0    1     0  \n",
       "2        1       0      0        1        1     0    0     1  \n",
       "3        0       0      1        0        0     1    2     0  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(text_data.toarray(), columns=trial.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10482848]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# the 0th and 2nd index lines are very different, a number close to 0\n",
    "cosine_similarity(text_data[0],text_data[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 0th and 3rd index lines are very similar, despite different lengths\n",
    "cosine_similarity(text_data[3],text_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
