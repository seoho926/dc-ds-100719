{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark Machine learning \n",
    "\n",
    "### Learning goals:\n",
    "- align the relationships between Hadoop, Spark\n",
    "- differentiate between Spark RDDs and Spark Dataframes and when each is appropriate\n",
    "- locate and explore the Spark.ML documentation\n",
    "- code along a text classification problem using four different ml algorithms, a data prep pipeline, and gridsearch to fine tune a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark context and concepts review\n",
    "<img src=\"https://images.pexels.com/photos/285173/pexels-photo-285173.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The story of Spark (in diagrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Start with Hadoop\n",
    "<img alt=\"diagram of hadoop v1 compared to hadoop v2\" src=\"img/yarn.png\" width=800>\n",
    "\n",
    "[diagram source](https://sites.google.com/site/codingbughunter/hadoop/yarn-general-discribe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Yarn facilitates the resource allocation between Spark and the HDFS\n",
    "### YARN = Yet Another Resource Negotiator\n",
    "#### YARN is a subproduct of Hadoop\n",
    "![yarn diagram with spark](http://hortonworks.com/wp-content/uploads/2013/06/YARN.png)\n",
    "\n",
    "[diagram source](https://sites.google.com/site/codingbughunter/hadoop/yarn-general-discribe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Then visualize the Spark ecosystem built on top of that\n",
    "\n",
    "<img alt=\"diagram of spark eco system components\" src=\"img/spark_eco.png\" width=600>\n",
    "\n",
    "[image source here](https://databricks.com/spark/about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The story of Spark (a timeline)\n",
    "\n",
    "|<p align=\"left justify\">Date</p>|<p align=\"left justify\">Product</p>|<p align=\"left justify\">Update</p>|\n",
    "|:----|:-----|:-----|\n",
    "| 2002 | Hadoop | <p align=\"left justify\">Doug Cutting starts `Apache Nutch` researching sort/merge processing</p> |\n",
    "| 2006 | Hadoop |  <p align=\"left justify\">Leaves `Nutch` and joins `Yahoo`, renaming the project `Hadoop` </p>|\n",
    "| 2008 | Hadoop |  <p align=\"left justify\">`Hadoop` was made `Apache’s` top level project </p> |\n",
    "| Jan 2008 | Hadoop |  <p align=\"left justify\">v 0.10.1 released </p>|\n",
    "| 2009 | Spark | <p align=\"left justify\">started as a research project at the UC Berkeley AMPLab  </p>|\n",
    "| 2010 | Spark |  <p align=\"left justify\">open sourced </p>|\n",
    "| Sept 2012 | Spark |  <p align=\"left justify\">0.6.0 released </p>|\n",
    "| 2013 | Spark |  <p align=\"left justify\">moved to the `Apache` Software Foundation </p>|\n",
    "| Feb 2013| Spark |  <p align=\"left justify\">Spark 0.7 adds a Python API called `PySpark` </p>|\n",
    "| Sept 2013 | Spark | <p align=\"left justify\">0.8.0 introduces `MLlib` </p>|\n",
    "| 2013 | Databricks |  <p align=\"left justify\">Original Spark research team at UC Berkeley found Databricks</p> |\n",
    "| May 2014 |Spark |  <p align=\"left justify\">v 1.0 introduces Spark SQL, for loading and manipulating structured data in Spark</p>|\n",
    "|Mar 2015 | Spark | <p align=\"left justify\"> v 1.3.0 brings a new DataFrame API</p> |\n",
    "| Jan 2016|  Spark | <p align=\"left justify\"> v 1.6.0 brings a new Dataset API </p> |\n",
    "| Jul 2016 | Spark | <p align=\"left justify\"> v 2.0.0 In Scala and Java, DataFrame and Dataset have been unified, i.e. DataFrame is just a type alias for Dataset of Row. In Python and R DataFrame is the main programming interface. <br> - SparkSession: new entry point that replaces the old SQLContext<br>- Native CSV data source, based on Databricks’ spark-csv module<br>- MLlib - The DataFrame-based API is now the primary API. The RDD-based API is entering maintenance mode </p> |\n",
    "| Jul 2017| Spark | <p align=\"left justify\"> v 2.2.0 drops support for Python 2.6 |\n",
    "| Nov 2018 | Spark | <p align=\"left justify\"> v 2.4.0<br> - This release adds Barrier Execution Mode for better integration with deep learning frameworks<br> - more integration between pandas UDF and spark DataFrames </p>|\n",
    "| Jan 2020| PySpark | <p align=\"left justify\"> Python 2 will be officially unsupported |\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark data objects\n",
    "\n",
    "<img alt=\"diagram of definitions of Spark objects from databricks\" src=\"https://databricks.com/wp-content/uploads/2018/05/rdd-1024x595.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Differences between objects:\n",
    "<img alt=\"memory usage\" src=\"https://databricks.com/wp-content/uploads/2016/07/memory-usage-when-caching-datasets-vs-rdds.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"type safety\" src=\"https://databricks.com/wp-content/uploads/2016/07/sql-vs-dataframes-vs-datasets-type-safety-spectrum.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use an RDD when:\n",
    "[quoted from databricks](https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html)\n",
    "\n",
    "> - you want low-level transformation and actions and control on your dataset;\n",
    "> - your data is unstructured, such as media streams or streams of text;\n",
    "> - you want to manipulate your data with functional programming constructs than domain specific expressions;\n",
    "> - you don’t care about imposing a schema, such as columnar format, while processing or accessing data attributes by name or column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use a dataframe when:\n",
    "[also quoted from databricks](https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html)\n",
    "\n",
    "\n",
    "> - you want rich semantics, high-level abstractions, and domain specific APIs, use DataFrame\n",
    "> - your processing demands high-level expressions, filters, maps, aggregation, averages, sum, SQL queries, columnar access and use of lambda functions on semi-structured data, use DataFrame\n",
    "> - you want higher degree of type-safety at compile time, want typed JVM objects, take advantage of Catalyst optimization, and benefit from Tungsten’s efficient code generation, use Dataset.\n",
    "> - you want unification and simplification of APIs across Spark Libraries, use DataFrame or Dataset.\n",
    "> - If you are a R user, use DataFrames.\n",
    "> - If you are a Python user, use DataFrames and resort back to RDDs if you need more control.\n",
    "\n",
    "**Note**: Machine learning algorithms are run on _DataFrames_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review:\n",
    "\n",
    "- You are grabbing live tweets about the CW show 'Jane the Virgin' for later analysis. In the Spark ecosystem, where should you store them? an RDD or a DataFrame?\n",
    "\n",
    "- You have an RDD of data that you wish to use to build a predictive model. Should you leave it as an RDD or transform it to a DataFrame?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.113.70.61:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11051b790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|24|M|technician|85711\r\n",
      "2|53|F|other|94043\r\n",
      "3|23|M|writer|32067\r\n",
      "4|24|M|technician|43537\r\n",
      "5|33|F|other|15213\r\n",
      "6|42|M|executive|98101\r\n",
      "7|57|M|administrator|91344\r\n",
      "8|36|M|administrator|05201\r\n",
      "9|29|M|student|01002\r\n",
      "10|53|M|lawyer|90703\r\n"
     ]
    }
   ],
   "source": [
    "!head data/users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "p_df = pd.read_csv('data/users.csv', sep='|') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <th>M</th>\n",
       "      <th>technician</th>\n",
       "      <th>85711</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>executive</td>\n",
       "      <td>98101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>91344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>05201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>01002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>90703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>30329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>06405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>29206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>scientist</td>\n",
       "      <td>55106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>educator</td>\n",
       "      <td>97301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>10309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>06355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>37212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>librarian</td>\n",
       "      <td>02138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>homemaker</td>\n",
       "      <td>95660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>30068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>40206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>artist</td>\n",
       "      <td>48197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>F</td>\n",
       "      <td>artist</td>\n",
       "      <td>94533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "      <td>engineer</td>\n",
       "      <td>55107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>engineer</td>\n",
       "      <td>21044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "      <td>30030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>55369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>55436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>artist</td>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>914</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>08105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>915</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>60614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>916</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>engineer</td>\n",
       "      <td>N2L5N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>917</td>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>20006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>918</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>scientist</td>\n",
       "      <td>70116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>919</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>other</td>\n",
       "      <td>14216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>920</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>artist</td>\n",
       "      <td>90008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>921</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>98801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>922</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>administrator</td>\n",
       "      <td>21114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>923</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>E2E3R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>924</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>other</td>\n",
       "      <td>11753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>925</td>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "      <td>salesman</td>\n",
       "      <td>49036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>926</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>01701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>927</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>55428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>928</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>55408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>929</td>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>scientist</td>\n",
       "      <td>53711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>930</td>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>scientist</td>\n",
       "      <td>07310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>931</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>33556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>932</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>06437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>933</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>48105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>934</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>engineer</td>\n",
       "      <td>22902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>935</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>doctor</td>\n",
       "      <td>66221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>936</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>other</td>\n",
       "      <td>32789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>937</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>98072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>938</td>\n",
       "      <td>38</td>\n",
       "      <td>F</td>\n",
       "      <td>technician</td>\n",
       "      <td>55038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>939</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>33319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>940</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>941</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>97229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>942</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "      <td>78209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>943</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>77841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  24  M     technician  85711\n",
       "0      2  53  F          other  94043\n",
       "1      3  23  M         writer  32067\n",
       "2      4  24  M     technician  43537\n",
       "3      5  33  F          other  15213\n",
       "4      6  42  M      executive  98101\n",
       "5      7  57  M  administrator  91344\n",
       "6      8  36  M  administrator  05201\n",
       "7      9  29  M        student  01002\n",
       "8     10  53  M         lawyer  90703\n",
       "9     11  39  F          other  30329\n",
       "10    12  28  F          other  06405\n",
       "11    13  47  M       educator  29206\n",
       "12    14  45  M      scientist  55106\n",
       "13    15  49  F       educator  97301\n",
       "14    16  21  M  entertainment  10309\n",
       "15    17  30  M     programmer  06355\n",
       "16    18  35  F          other  37212\n",
       "17    19  40  M      librarian  02138\n",
       "18    20  42  F      homemaker  95660\n",
       "19    21  26  M         writer  30068\n",
       "20    22  25  M         writer  40206\n",
       "21    23  30  F         artist  48197\n",
       "22    24  21  F         artist  94533\n",
       "23    25  39  M       engineer  55107\n",
       "24    26  49  M       engineer  21044\n",
       "25    27  40  F      librarian  30030\n",
       "26    28  32  M         writer  55369\n",
       "27    29  41  M     programmer  94043\n",
       "28    30   7  M        student  55436\n",
       "29    31  24  M         artist  10003\n",
       "..   ...  .. ..            ...    ...\n",
       "912  914  44  F          other  08105\n",
       "913  915  50  M  entertainment  60614\n",
       "914  916  27  M       engineer  N2L5N\n",
       "915  917  22  F        student  20006\n",
       "916  918  40  M      scientist  70116\n",
       "917  919  25  M          other  14216\n",
       "918  920  30  F         artist  90008\n",
       "919  921  20  F        student  98801\n",
       "920  922  29  F  administrator  21114\n",
       "921  923  21  M        student  E2E3R\n",
       "922  924  29  M          other  11753\n",
       "923  925  18  F       salesman  49036\n",
       "924  926  49  M  entertainment  01701\n",
       "925  927  23  M     programmer  55428\n",
       "926  928  21  M        student  55408\n",
       "927  929  44  M      scientist  53711\n",
       "928  930  28  F      scientist  07310\n",
       "929  931  60  M       educator  33556\n",
       "930  932  58  M       educator  06437\n",
       "931  933  28  M        student  48105\n",
       "932  934  61  M       engineer  22902\n",
       "933  935  42  M         doctor  66221\n",
       "934  936  24  M          other  32789\n",
       "935  937  48  M       educator  98072\n",
       "936  938  38  F     technician  55038\n",
       "937  939  26  F        student  33319\n",
       "938  940  32  M  administrator  02215\n",
       "939  941  20  M        student  97229\n",
       "940  942  48  F      librarian  78209\n",
       "941  943  22  M        student  77841\n",
       "\n",
       "[942 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"data/users.csv\").map(lambda line: line.split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '24', 'M', 'technician', '85711'],\n",
       " ['2', '53', 'F', 'other', '94043'],\n",
       " ['3', '23', 'M', 'writer', '32067'],\n",
       " ['4', '24', 'M', 'technician', '43537'],\n",
       " ['5', '33', 'F', 'other', '15213']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"data/users.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='1', _c1='24', _c2='M', _c3='technician', _c4='85711'),\n",
       " Row(_c0='2', _c1='53', _c2='F', _c3='other', _c4='94043'),\n",
       " Row(_c0='3', _c1='23', _c2='M', _c3='writer', _c4='32067'),\n",
       " Row(_c0='4', _c1='24', _c2='M', _c3='technician', _c4='43537'),\n",
       " Row(_c0='5', _c1='33', _c2='F', _c3='other', _c4='15213')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively:\n",
    "from_pandas_df = spark.createDataFrame(p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='1', _c1='24', _c2='M', _c3='technician', _c4='85711'),\n",
       " Row(_c0='2', _c1='53', _c2='F', _c3='other', _c4='94043'),\n",
       " Row(_c0='3', _c1='23', _c2='M', _c3='writer', _c4='32067'),\n",
       " Row(_c0='4', _c1='24', _c2='M', _c3='technician', _c4='43537'),\n",
       " Row(_c0='5', _c1='33', _c2='F', _c3='other', _c4='15213')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's already a DF, but this is the easy way to rename columns\n",
    "df = (spark.read.csv(\"data/users.csv\", sep=\"|\")\n",
    "           .toDF(\"id\", \"age\", \"gender\", \"occupation\", \"zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    df.where(\"occupation != 'other'\")\n",
    "      .groupby(\"occupation\")\n",
    "      .count()\n",
    "      .sort(\"count\", ascending=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[occupation: string, count: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupation</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>student</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>educator</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>administrator</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engineer</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>programmer</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      occupation  count\n",
       "0        student    196\n",
       "1       educator     95\n",
       "2  administrator     79\n",
       "3       engineer     67\n",
       "4     programmer     66"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.limit(5).toPandas()\n",
    "# df.head()\n",
    "result.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT occupation)|\n",
      "+--------------------------+\n",
      "|                        21|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df.agg(F.countDistinct('occupation')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|   occupation|count|\n",
      "+-------------+-----+\n",
      "|      student|  196|\n",
      "|        other|  105|\n",
      "|     educator|   95|\n",
      "|administrator|   79|\n",
      "|     engineer|   67|\n",
      "|   programmer|   66|\n",
      "|    librarian|   51|\n",
      "|       writer|   45|\n",
      "|    executive|   32|\n",
      "|    scientist|   31|\n",
      "+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also use SQL to query\n",
    "df.createOrReplaceTempView('users')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT occupation, COUNT(*) as count\n",
    "FROM users\n",
    "GROUP BY occupation\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "output = spark.sql(query)\n",
    "output.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
