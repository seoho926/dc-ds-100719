
# Module 5 Final Project

## Final Project Summary

Congratulations! You've made it through another _intense_ module, and now you're ready to show off your newfound machine learning skills!

![awesome](https://raw.githubusercontent.com/learn-co-curriculum/dsc-mod-5-project/master/smart.gif)

All that remains for Module 5 is to complete the final project!

## The Project

For this project, you're going to select a dataset of your choosing and create a classification model. You'll start by identifying a problem you can solve with classification, and then identify a dataset. You'll then use everything you've learned about data science and machine learning thus far to source a dataset, preprocess and explore it, and then build and interpret a classification model that answers your chosen question.


### Selecting a Data Set

We encourage you to be very thoughtful when identifying your problem and selecting your data set--an overscoped project goal or a poor data set can quickly bring an otherwise promising project to a grinding halt.

To help you select an appropriate data set for this project, we've set some guidelines:

1. Your dataset should work for classification. The classification task can be either binary or multiclass, as long as it's a classification model.   

2. Your dataset needs to be of sufficient complexity. Try to avoid picking an overly simple dataset. Avoid extremely small datasets as well as the most common datasets like titanic, iris, MNIST, etc. We want to see all the steps of the Data Science Process in this project--it's okay if the dataset is mostly clean, but we expect to see some preprocessing and exploration. See the following section, **_Data Set Constraints_**, for more information on this.   

3. On the other end of the spectrum, don't pick a problem that's too complex, either. Stick to problems that you have a clear idea of how you can use machine learning to solve it. For now, we recommend you stay away from overly complex problems in the domains of natural language processing or computer vision.  Although those domains make use of supervised learning, they come with a lot of other special requirements and techniques that you don't know yet (but you'll learn soon!). If you're chosen problem feels like you've overscoped, then it probably is. If you aren't sure if your problem scope is appropriate, double check with your instructors!  

4. **_Serious Bonus Points_** if some or all of the data is data you have to source yourself through web scraping or interacting with a 3rd party API! Having projects that show off your ability to source data effectively make you look that much more impressive when showing your work off to potential employers!

### Data Set Constraints

When selecting a data set, be sure to take into consideration the following constraints:

1. Your data set can't be one we've already worked with in any labs.
2. Your data set should contain a minimum of 1000 rows.    
3. Your data set should contain a minimum of 10 predictor columns, before any one-hot encoding is performed.   
4. Your instructors must provide final approval on your data set.

## The Deliverables

For online students, your completed project should contain the following four deliverables:

1. A **_Narrative Jupyter Notebook_** containing a summary of the code you've written for this project. The narrative aspect should walk us through the obeservations you made, the actions you took, and the results+analysis of those results. This work will need to be pushed to your GitHub repository in order to submit your project.

You may have additional Jupyter notebooks that show specific aspects of your project that might not help tell the story of your analysis.  This might include EDA, exploration and model building that proved fruitless, or visualizations that you're proud of but don't contribute to the narrative.

2. An organized **README.md** file in the GitHub repository that describes the contents of the repository. This file should be the source of information for navigating through the repository. 

4. A **_Non-Technical Slide Deck** that gives a brief overview of your problem/dataset, and the pertinent steps of the OSEMN process.  This should be roughly 8 slides and take no more than five minutes.


### Jupyter Notebook Must-Haves

For this project, your Jupyter Notebook should meet the following specifications:

**_Organization/Code Cleanliness_**

* The notebook should be well organized, easy to follow, and code is commented where appropriate.  
    * Level Up: The notebook contains well-formatted, professional looking markdown cells explaining any substantial code. All functions have docstrings that act as professional-quality documentation.  
* The notebook is written to technical audiences with a way to both understand your approach and reproduce your results. The target audience for this deliverable is other data scientists looking to validate your findings.  

**_Process, Methodology, and Findings_**

* Your notebook should contain a clear record of your process and methodology for exploring and preprocessing your data, building and tuning a model, and interpreting your results.
* We recommend you use the OSEMN process to help organize your thoughts and stay on track.


## Grading Rubric 

A PDF of the generic grading rubric for the project can be found [here](module5_project_rubric.pdf).  This should be viewed as a template and not a strict rubric.  Please confirm any confusions with an instructor.

## Groups

Mod 5's project will be a choose-your-own-adventure situation!  Groups of two are required, but it is up to **you** to pick them.  Let your instructors know your group pairings no later than Friday, 12/3 at 9:30am via **Slack to Ammar**.

## Timeline

- 12/12 - project kickoff. Form groups!
- 12/13, 9:30am - deadline to let instructors know groupings
- 12/13, 2:00pm - deadline to let instructors know your problem and your dataset (via a form that will be sent out)
- 12/16, 2:30pm - check-in with coaches
- 12/17, 9:30am - check-in with lead instructor
- 12/18, 3:00pm - presentation & mini Science Fair

