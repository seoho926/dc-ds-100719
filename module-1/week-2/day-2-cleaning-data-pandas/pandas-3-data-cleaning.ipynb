{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catch-Up from Yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping a DataFrame\n",
    "\n",
    "### `.pivot()` and `.pivot_table()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those of you familiar with Excel have probably used Pivot Tables. Pandas has a similar functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "uci = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci.pivot(values = 'sex', columns = 'target').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci.pivot_table(values = 'chol', index = 'sex', columns = 'target', aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for Combining DataFrames: `.join()`, `.merge()`, `.concat()`, `.melt()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy1 = pd.DataFrame([[63, 142], [33, 47]], columns = ['age', 'HP'])\n",
    "toy2 = pd.DataFrame([[63, 100], [33, 200]], columns = ['age', 'HP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy1.join(toy2.set_index('age'),\n",
    "          on = 'age',\n",
    "          lsuffix = '_1',\n",
    "          rsuffix = '_2').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.merge()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chars = pd.read_csv('ds_chars.csv', index_col = 0)\n",
    "ds_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_csv('states.csv', index_col = 0)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chars.merge(states,\n",
    "               left_on='home_state',\n",
    "               right_on = 'state',\n",
    "               how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pd.concat()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Look up the documentation on pd.concat (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) and use it to concatenate ds_chars and states.\n",
    "<br/>\n",
    "Your result should still have only five rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ds_chars, states], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pd.melt()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melting removes the structure from your DataFrame and puts the data in a 'variable' and 'value' format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(ds_chars,\n",
    "        id_vars=['name'],\n",
    "        value_vars=['HP', 'home_state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing it all together with the Animal Shelter Data\n",
    "\n",
    "Join the data from the [Austin Animal Shelter Intake dataset](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm) to the outcomes dataset by Animal ID.\n",
    "\n",
    "Use the dates from each dataset to see how long animals spend in the shelter. Does it differ by time of year? By outcome?\n",
    "\n",
    "The Url for the Intake Dataset is here: https://data.austintexas.gov/api/views/wter-evkm/rows.csv?accessType=DOWNLOAD\n",
    "\n",
    "_Hints_ :\n",
    "- import and clean the intake dataset first\n",
    "- use apply/applymap/lambda to change the variables to their proper format in the intake data\n",
    "- rename the columns in the intake dataset *before* joining\n",
    "- create a new days-in-shelter variable\n",
    "- Notice that some values in \"days_in_shelter\" column are NaN or values < 0 (remove these rows using the \"<\" operator and ~is.na())\n",
    "- Use group_by to get some interesting information about the dataset\n",
    "\n",
    "Make sure to export and save your cleaned dataset. We will use it in a later lecture!\n",
    "\n",
    "use the notation `df.to_csv()` to write the `df` to a csv. Read more about the `to_csv()` documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "As data scientists, we want to build a model to predict the sale price of a house in Seattle in 2019, based on its square footage. We know that the King County Department of Assessments has comprehensive data available on real property sales in the Seattle area. We need to prepare the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, get the data!\n",
    "\n",
    "When working on a project involving data that can fit on our computer, we store it in a `data` directory.\n",
    "\n",
    "```bash\n",
    "cd <project_directory>  # example: cd ~/flatiron_ds/pandas-3\n",
    "mkdir data\n",
    "cd data\n",
    "```\n",
    "\n",
    "Note that `<project_directory>` in angle brackets is a _placeholder_. You should type the path to the actual location on your computer where you're working on this project. Do not literally type `<project_directory>` and _do not type the angle brackets_. You can see an example in the _comment_ to the right of the command above.\n",
    "\n",
    "Now, we'll need to download the two data files that we need. I will send those zipped files to you in Slack.\n",
    "\n",
    "\n",
    "Note that there are spaces in the file name. Even though you will *never put spaces in filenames*, you may need to deal with spaces that _other_ people have used in filenames.\n",
    "\n",
    "There are two ways to handle the spaces in these filenames when referencing them at the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. You can _escape_ the spaces by putting a backslash (`\\`, remember _backslash is next to backspace_) before each one:\n",
    "\n",
    "`unzip Real\\ Property\\ Sales.zip`\n",
    "\n",
    "This is what happens if you tab-complete the filename in the terminal. Tab completion is your friend!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. You can put the entire filename in quotes:\n",
    "\n",
    "`unzip \"Real Property Sales.zip\"`\n",
    "\n",
    "Try unzipping these files with the `unzip` command. The `unzip` command takes one argument, the name of the file that you want to unzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('data/Real Property Sales.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing pink? Warnings are useful!\n",
    "\n",
    "Note the warning above: `DtypeWarning: Columns (1, 2) have mixed types.` Because we start with an index of zero, the columns that we're being warned about are actually the _second_ and _third_ columns, `sales_df['Major']` and `sales_df['Minor']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overload?\n",
    "\n",
    "That's a lot of columns. We're only interested in identifying the date, sale price, and square footage of each specific property. What can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df[['Major', 'Minor', 'DocumentDate', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df = pd.read_csv('data/Residential Building.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another warning! Which column has index 11?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_df.columns[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ZipCode` seems like a potentially useful column. We'll need it to determine which house sales took place in Seattle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So many features!\n",
    "\n",
    "As data scientists, we should be _very_ cautious about discarding potentially useful data. But, today, we're interested in _only_ the total square footage of each property. What can we do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_df = bldg_df[['Major', 'Minor', 'SqFtTotLiving', 'ZipCode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.merge(sales_df, bldg_df, on=['Major', 'Minor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error!\n",
    "\n",
    "Why are we seeing an error when we try to join the dataframes?\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><pre>\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 2013160 entries, 0 to 2013159\n",
    "Data columns (total 4 columns):\n",
    "Major           object\n",
    "Minor           object\n",
    "DocumentDate    object\n",
    "SalePrice       int64\n",
    "dtypes: int64(1), object(3)\n",
    "memory usage: 61.4+ MB</pre></td>\n",
    "        <td style=\"text-align:left\"><pre>\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 511359 entries, 0 to 511358\n",
    "Data columns (total 4 columns):\n",
    "Major            511359 non-null int64\n",
    "Minor            511359 non-null int64\n",
    "SqFtTotLiving    511359 non-null int64\n",
    "ZipCode          468345 non-null object\n",
    "dtypes: int64(3), object(1)\n",
    "memory usage: 15.6+ MB\n",
    "</pre></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Review the error message in light of the above:\n",
    "\n",
    "* `ValueError: You are trying to merge on object and int64 columns.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Major'] = pd.to_numeric(sales_df['Major'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error!\n",
    "\n",
    "Note the useful error message above:\n",
    "\n",
    "`ValueError: Unable to parse string \"      \" at position 936643`\n",
    "\n",
    "In this case, we want to treat non-numeric values as missing values. Let's see if there's a way to change how the `pd.to_numeric` function handles errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The single question mark means \"show me the docstring\"\n",
    "pd.to_numeric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the part that we're looking for:\n",
    "```\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If 'raise', then invalid parsing will raise an exception\n",
    "    - If 'coerce', then invalid parsing will be set as NaN\n",
    "    - If 'ignore', then invalid parsing will return the input\n",
    "```\n",
    "\n",
    "Let's try setting the `errors` parameter to `'coerce'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Major'] = pd.to_numeric(sales_df['Major'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Let's do the same thing with the `Minor` parcel number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Minor'] = pd.to_numeric(sales_df['Minor'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try our join again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.merge(sales_df, bldg_df, on=['Major', 'Minor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see right away that we're missing zip codes for many of the sales transactions. (1321536 non-null entries for ZipCode is fewer than the 1436772 entries in the dataframe.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.loc[sales_data['ZipCode'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are interested in finding houses in Seattle zip codes, we will need to drop the rows with missing zip codes.\n",
    "\n",
    "*Note:* we can use [Boolean Indexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing) to select all the rows where there are no missing zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data2 = sales_data.loc[~sales_data['ZipCode'].isna(), :]\n",
    "sales_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An alternative method to drop missing is `.dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data3=sales_data.dropna()\n",
    "sales_data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn: Data Cleaning with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Investigate and drop rows with invalid values in the SalePrice and SqFtTotLiving columns.\n",
    "\n",
    "Use multiple notebook cells to accomplish this! Press `[esc]` then `B` to create a new cell below the current cell. Press `[return]` to start typing in the new cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Investigate and handle non-numeric ZipCode values\n",
    "\n",
    "Can you find a way to shorten ZIP+4 codes to the first five digits?\n",
    "\n",
    "What's the right thing to do with missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the error message and decide how to fix it.\n",
    "# Note: using errors='coerce' is the *wrong* choice in this case.\n",
    "def is_integer(x):\n",
    "    try:\n",
    "        _ = int(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "sales_data.loc[sales_data['ZipCode'].apply(is_integer) == False, 'ZipCode'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add a column for PricePerSqFt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Subset the data to 2019 sales only.\n",
    "\n",
    "We can assume that the DocumentDate is approximately the sale date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Subset the data to zip codes within the City of Seattle.\n",
    "\n",
    "You'll need to find a list of Seattle zip codes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is the mean price per square foot for a house sold in Seattle in 2019?\n",
    "\n",
    "Don't just type the answer. Type code that generates the answer as output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
